{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c220a39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths & URLs\n",
    "\n",
    "import os\n",
    "\n",
    "# Enable CUDA stacktrace reporting for debugging\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Directorio base\n",
    "#PATH_BASE = '/content/drive/MyDrive/proximity'\n",
    "PATH_BASE = 'C:\\\\Users\\\\User\\\\Documents\\\\Proyecto Proximity'\n",
    "\n",
    "# Data release 70\n",
    "DR70_PATH = os.path.join(PATH_BASE, 'DR70')\n",
    "DR70_CT_PATH = os.path.join(DR70_PATH, 'datalake_sorted')\n",
    "DR70_LABELS_PATH = os.path.join(DR70_PATH, 'labels.csv')\n",
    "\n",
    "# Data release 176\n",
    "DR176_PATH = os.path.join(PATH_BASE, 'DR176')\n",
    "DR176_CT_PATH = os.path.join(DR176_PATH, 'DR176_studies')\n",
    "DR176_LABELS_PATH = os.path.join(PATH_BASE, 'reports_with_label.csv')\n",
    "\n",
    "\n",
    "# CTs in Nibabel format\n",
    "CT_NIBABEL_PATH = os.path.join(PATH_BASE, 'DR70', 'CTs')\n",
    "\n",
    "# Embeddings visuales de CTs\n",
    "#CT_EMBEDDINGS_PATH = DATA_RELEASE_PATH + '/visual_embeddings'\n",
    "\n",
    "\n",
    "# Etiquetas de los CTs del data release actual\n",
    "#CT_LABELS_CSV_PATH = DATA_RELEASE_PATH + '/labels.csv'\n",
    "\n",
    "# Data release (CTs + etiquetas) organizados en un DataFrame\n",
    "#CT_DATASET_DF_HDF_PATH = os.path.join(PATH_BASE, 'dataset_df.h5')\n",
    "#CT_DATASET_DF_PICKLE_PATH = os.path.join(PATH_BASE, 'dataset_df.pickle')\n",
    "\n",
    "# URLs de modelos visuales\n",
    "#RESNET18_URL = 'microsoft/resnet-18'\n",
    "\n",
    "# Path que contiene los resnet50 embeddings de CTs del data release actual\n",
    "#CT_RESNET18_EMBEDDINGS_PATH = os.path.join(DR70_PATH, 'visual_embeddings', 'resnet18')\n",
    "#CT_RESNET18_EMBEDDINGS_PATH = os.path.join(DR70_PATH, 'visual_embeddings', 'resnet18', 'reshaped_averaged')\n",
    "\n",
    "# Path de modelos entrenados en base a tripletas\n",
    "TRIPLET_MODELS_PATH = os.path.join(PATH_BASE, 'retrieval_models', 'triplets')\n",
    "TRIPLET_CHECKPOINTS_PATH = os.path.join(PATH_BASE, 'retrieval_models', 'triplets', 'checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe87a37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsize_diff = len(dataset) - train_size - val_size - test_size\\ntrain_size += size_diff\\n\\n# Use random_split to split the dataset\\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\\n\\n\\ntraining_sampler = RandomSampler(train_dataset, replacement=False, generator=torch.Generator().manual_seed(42))\\nbatch_sampler = BatchSampler(sampler=training_sampler, batch_size=8, drop_last=True)\\n\\ntraining_dataloader = torch.utils.data.DataLoader(\\n    train_dataset, \\n    batch_size=8, \\n    shuffle=True, \\n    generator=torch.Generator().manual_seed(42)\\n)\\nct_embedding_model = CTModel()\\ntriplet_model = TripletModel(model=ct_embedding_model, mode=\\'HN\\', seed=42)\\n\\ne = dataset.get_updated_embeddings(triplet_model, torch.device(\"cuda\"))\\n\\nprint(dataset.get_embeddings([0]))\\n\\n\\ntraining_sampler = RandomSampler(train_dataset, replacement=False, generator=torch.Generator().manual_seed(42))\\nval_sampler = RandomSampler(val_dataset, replacement=False, generator=torch.Generator().manual_seed(42))\\n\\nprint(train_dataset[:][0])\\nprint(val_dataset[:][0])\\nprint([e for e in training_sampler])\\nprint([e for e in val_sampler])\\n\\n\\n# You can now create data loaders for each split if needed\\n\\n# Create a RandomSampler with seed 42 and no replacement\\ntraining_sampler = RandomSampler(train_dataset, replacement=False, generator=torch.Generator().manual_seed(42))\\nbatch_sampler = BatchSampler(sampler=training_sampler, batch_size=8, drop_last=True)\\n        \\n\\n\\nimport time\\nlim = 99\\nfor batch in batch_sampler:\\n    if lim == 0:\\n        break\\n    lim -= 1\\n    print(\\'\\')\\n    print(\\'Batch:\\', batch)  # Do whatever you want with the batch data\\n    ids = list()\\n    sample_data = list()\\n    labels_data = list()\\n    idx, sample, labels = dataset[batch]\\n    print(\\'Labels:\\', labels_data)\\n    positive, negative = dataset.get_batch_positive_negative_pairs(batch)\\n    print(\\'Positive pairs:\\', positive)\\n    print(\\'Negative pairs:\\', negative)\\n    print(\\'sample shape\\', sample.shape)\\n    time.sleep(0.5) # just to make the logging and prints to output in the correct order!\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#Set seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "\n",
    "\"\"\"CT volume preprocessing functions\"\"\"\n",
    "\n",
    "#############################################\n",
    "# Pixel Values (on torch Tensors for speed) #-----------------------------------\n",
    "#############################################\n",
    "def normalize(ctvol, lower_bound, upper_bound): #Done testing\n",
    "    \"\"\"Clip images and normalize\"\"\"\n",
    "    #formula https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range\n",
    "    ctvol = torch.clamp(ctvol, lower_bound, upper_bound)\n",
    "    ctvol = (ctvol - lower_bound) / (upper_bound - lower_bound)\n",
    "    return ctvol\n",
    "\n",
    "def torchify_pixelnorm_pixelcenter(ctvol, pixel_bounds):\n",
    "    \"\"\"Normalize using specified pixel_bounds and then center on the ImageNet\n",
    "    mean. Used in 2019_10 dataset preparation\"\"\"\n",
    "    #Cast to torch Tensor\n",
    "    #use torch Tensor instead of numpy array because addition, subtraction,\n",
    "    #multiplication, and division are faster in torch Tensors than np arrays\n",
    "    ctvol = torch.from_numpy(ctvol).type(torch.float)\n",
    "    \n",
    "    #Clip Hounsfield units and normalize pixel values\n",
    "    ctvol = normalize(ctvol, pixel_bounds[0], pixel_bounds[1])\n",
    "    \n",
    "    #Center on the ImageNet mean since you are using an ImageNet pretrained\n",
    "    #feature extractor:\n",
    "    ctvol = ctvol - 0.449\n",
    "    return ctvol\n",
    "\n",
    "###########\n",
    "# Padding #---------------------------------------------------------------------\n",
    "###########\n",
    "def pad_slices(ctvol, max_slices): #Done testing\n",
    "    \"\"\"For <ctvol> of shape (slices, side, side) pad the slices to shape\n",
    "    max_slices for output of shape (max_slices, side, side)\"\"\"\n",
    "    padding_needed = max_slices - ctvol.shape[0]\n",
    "    assert (padding_needed >= 0), 'Image slices exceed max_slices by'+str(-1*padding_needed)\n",
    "    if padding_needed > 0:\n",
    "        before_padding = int(padding_needed/2.0)\n",
    "        after_padding = padding_needed - before_padding\n",
    "        ctvol = np.pad(ctvol, pad_width = ((before_padding, after_padding), (0,0), (0,0)),\n",
    "                     mode = 'constant', constant_values = np.amin(ctvol))\n",
    "        assert ctvol.shape[0]==max_slices\n",
    "    return ctvol\n",
    "\n",
    "def pad_sides(ctvol, max_side_length): #Done testing\n",
    "    \"\"\"For <ctvol> of shape (slices, side, side) pad the sides to shape\n",
    "    max_side_length for output of shape (slices, max_side_length,\n",
    "    max_side_length)\"\"\"\n",
    "    needed_padding = 0\n",
    "    for side in [1,2]:\n",
    "        padding_needed = max_side_length - ctvol.shape[side]\n",
    "        if padding_needed > 0:\n",
    "            before_padding = int(padding_needed/2.0)\n",
    "            after_padding = padding_needed - before_padding\n",
    "            if side == 1:\n",
    "                ctvol = np.pad(ctvol, pad_width = ((0,0), (before_padding, after_padding), (0,0)),\n",
    "                         mode = 'constant', constant_values = np.amin(ctvol))\n",
    "                needed_padding += 1\n",
    "            elif side == 2:\n",
    "                ctvol = np.pad(ctvol, pad_width = ((0,0), (0,0), (before_padding, after_padding)),\n",
    "                         mode = 'constant', constant_values = np.amin(ctvol))\n",
    "                needed_padding += 1\n",
    "    if needed_padding == 2: #if both sides needed to be padded, then they\n",
    "        #should be equal (but it's possible one side or both were too large\n",
    "        #in which case we wouldn't expect them to be equal)\n",
    "        assert ctvol.shape[1]==ctvol.shape[2]==max_side_length\n",
    "    return ctvol\n",
    "\n",
    "def pad_volume(ctvol, max_slices, max_side_length):\n",
    "    \"\"\"Pad <ctvol> to a minimum size of\n",
    "    [max_slices, max_side_length, max_side_length], e.g. [402, 308, 308]\n",
    "    Used in 2019_10 dataset preparation\"\"\"\n",
    "    if ctvol.shape[0] < max_slices:\n",
    "        ctvol = pad_slices(ctvol, max_slices)\n",
    "    if ctvol.shape[1] < max_side_length:\n",
    "        ctvol = pad_sides(ctvol, max_side_length)\n",
    "    return ctvol\n",
    "\n",
    "###########################\n",
    "# Reshaping to 3 Channels #-----------------------------------------------------\n",
    "###########################\n",
    "def sliceify(ctvol): #Done testing\n",
    "    \"\"\"Given a numpy array <ctvol> with shape [slices, square, square]\n",
    "    reshape to 'RGB' [max_slices/3, 3, square, square]\"\"\"\n",
    "    return np.reshape(ctvol, newshape=[int(ctvol.shape[0]/3), 3, ctvol.shape[1], ctvol.shape[2]])\n",
    "\n",
    "def reshape_3_channels(ctvol):\n",
    "    \"\"\"Reshape grayscale <ctvol> to a 3-channel image\n",
    "    Used in 2019_10 dataset preparation\"\"\"\n",
    "    if ctvol.shape[0]%3 == 0:\n",
    "        ctvol = sliceify(ctvol)\n",
    "    else:\n",
    "        if (ctvol.shape[0]-1)%3 == 0:\n",
    "            ctvol = sliceify(ctvol[:-1,:,:])\n",
    "        elif (ctvol.shape[0]-2)%3 == 0:\n",
    "            ctvol = sliceify(ctvol[:-2,:,:])\n",
    "    return ctvol\n",
    "\n",
    "##################################\n",
    "# Cropping and Data Augmentation #----------------------------------------------\n",
    "##################################\n",
    "def crop_specified_axis(ctvol, max_dim, axis): #Done testing\n",
    "    \"\"\"Crop 3D volume <ctvol> to <max_dim> along <axis>\"\"\"\n",
    "    dim = ctvol.shape[axis]\n",
    "    if dim > max_dim:\n",
    "        amount_to_crop = dim - max_dim\n",
    "        part_one = int(amount_to_crop/2.0)\n",
    "        part_two = dim - (amount_to_crop - part_one)\n",
    "        if axis == 0:\n",
    "            return ctvol[part_one:part_two, :, :]\n",
    "        elif axis == 1:\n",
    "            return ctvol[:, part_one:part_two, :]\n",
    "        elif axis == 2:\n",
    "            return ctvol[:, :, part_one:part_two]\n",
    "    else:\n",
    "        return ctvol\n",
    "\n",
    "def single_crop_3d_fixed(ctvol, max_slices, max_side_length):\n",
    "    \"\"\"Crop a single 3D volume to shape [max_slices, max_side_length,\n",
    "    max_side_length]\"\"\"\n",
    "    ctvol = crop_specified_axis(ctvol, max_slices, 0)\n",
    "    ctvol = crop_specified_axis(ctvol, max_side_length, 1)\n",
    "    ctvol = crop_specified_axis(ctvol, max_side_length, 2)\n",
    "    return ctvol\n",
    "\n",
    "def single_crop_3d_augment(ctvol, max_slices, max_side_length):\n",
    "    \"\"\"Crop a single 3D volume to shape [max_slices, max_side_length,\n",
    "    max_side_length] with randomness in the centering and random\n",
    "    flips or rotations\"\"\"\n",
    "    #Introduce random padding so that the centered crop will be slightly random\n",
    "    ctvol = rand_pad(ctvol)\n",
    "    \n",
    "    #Obtain the center crop\n",
    "    ctvol = single_crop_3d_fixed(ctvol, max_slices, max_side_length)\n",
    "    \n",
    "    #Flip and rotate\n",
    "    ctvol = rand_flip(ctvol)\n",
    "    ctvol = rand_rotate(ctvol)\n",
    "    \n",
    "    #Make contiguous array to avoid Pytorch error\n",
    "    return np.ascontiguousarray(ctvol)\n",
    "\n",
    "def rand_pad(ctvol):\n",
    "    \"\"\"Introduce random padding between 0 and 15 pixels on each of the 6 sides\n",
    "    of the <ctvol>\"\"\"\n",
    "    randpad = np.random.randint(low=0,high=15,size=(6))\n",
    "    ctvol = np.pad(ctvol, pad_width = ((randpad[0],randpad[1]), (randpad[2],randpad[3]), (randpad[4], randpad[5])),\n",
    "                         mode = 'constant', constant_values = np.amin(ctvol))\n",
    "    return ctvol\n",
    "    \n",
    "def rand_flip(ctvol):\n",
    "    \"\"\"Flip <ctvol> along a random axis with 50% probability\"\"\"\n",
    "    if np.random.randint(low=0,high=100) < 50:\n",
    "        chosen_axis = np.random.randint(low=0,high=3) #0, 1, and 2 are axis options\n",
    "        ctvol =  np.flip(ctvol, axis=chosen_axis)\n",
    "    return ctvol\n",
    "\n",
    "def rand_rotate(ctvol):\n",
    "    \"\"\"Rotate <ctvol> some random amount axially with 50% probability\"\"\"\n",
    "    if np.random.randint(low=0,high=100) < 50:\n",
    "        chosen_k = np.random.randint(low=0,high=4)\n",
    "        ctvol = np.rot90(ctvol, k=chosen_k, axes=(1,2))\n",
    "    return ctvol\n",
    "\n",
    "###########################################\n",
    "# 2019_10 Dataset Preprocessing Sequences #-------------------------------------\n",
    "###########################################\n",
    "def prepare_ctvol_2019_10_dataset(ctvol, pixel_bounds, data_augment, num_channels,\n",
    "                                  crop_type):\n",
    "    \"\"\"Pad, crop, possibly augment, reshape to correct\n",
    "    number of channels, cast to torch tensor (to speed up subsequent operations),\n",
    "    Clip Hounsfield units, normalize pixel values, center on the\n",
    "    ImageNet mean, and return as a torch tensor (for crop_type='single')\n",
    "    \n",
    "    <pixel_bounds> is a list of ints e.g. [-1000,200] Hounsfield units. Used for\n",
    "        pixel value clipping and normalization.\n",
    "    <data_augment> is True to employ data augmentation, and False otherwise\n",
    "    <num_channels> is an int, e.g. 3 to reshape the grayscale volume into\n",
    "        a volume of 3-channel images\n",
    "    <crop_type>: if 'single' then return the volume as one 3D numpy array.\"\"\"\n",
    "    max_slices = 402\n",
    "    max_side_length = 512\n",
    "    assert num_channels == 3 or num_channels == 1\n",
    "    assert crop_type == 'single'\n",
    "    \n",
    "    #Padding to minimum size [max_slices, max_side_length, max_side_length]\n",
    "    ctvol = pad_volume(ctvol, max_slices, max_side_length)\n",
    "    \n",
    "    #Cropping, and data augmentation if indicated\n",
    "    if crop_type == 'single':\n",
    "        if data_augment is True:\n",
    "            ctvol = single_crop_3d_augment(ctvol, max_slices, max_side_length)\n",
    "        else:\n",
    "            ctvol = single_crop_3d_fixed(ctvol, max_slices, max_side_length)\n",
    "        #Reshape to 3 channels if indicated\n",
    "        if num_channels == 3:\n",
    "            ctvol = reshape_3_channels(ctvol)\n",
    "        #Cast to torch tensor and deal with pixel values\n",
    "        output = torchify_pixelnorm_pixelcenter(ctvol, pixel_bounds)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "# PACE Dataset for Data Stored in 2019-10-BigData #-----------------------------\n",
    "###################################################\n",
    "class CTDataset_2019_10(Dataset):    \n",
    "    def __init__(self, setname, label_type_ld,\n",
    "                 label_meanings, num_channels, pixel_bounds,\n",
    "                 data_augment, crop_type,\n",
    "                 selected_note_acc_files):\n",
    "        \"\"\"CT Dataset class that works for preprocessed data in 2019-10-BigData.\n",
    "        A single example (for crop_type == 'single') is a 4D CT volume:\n",
    "            if num_channels == 3, shape [134,3,420,420]\n",
    "            if num_channels == 1, shape [402,420,420]\n",
    "        \n",
    "        Variables:\n",
    "        <setname> is either 'train' or 'valid' or 'test'\n",
    "        <label_type_ld> is 'disease_new'\n",
    "        <label_meanings>: list of strings indicating which labels should\n",
    "            be kept. Alternatively, can be the string 'all' in which case\n",
    "            all labels are kept.\n",
    "        <num_channels>: number of channels to reshape the image to.\n",
    "            == 3 if the model uses a pretrained feature extractor.\n",
    "            == 1 if the model uses only 3D convolutions.\n",
    "        <pixel_bounds>: list of ints e.g. [-1000,200]\n",
    "            Determines the lower bound, upper bound of pixel value clipping\n",
    "            and normalization.\n",
    "        <data_augment>: if True, perform data augmentation.\n",
    "        <crop_type>: is 'single' for an example consisting of one 4D numpy array\n",
    "        <selected_note_acc_files>: This should be a dictionary\n",
    "            with key equal to setname and value that is a string. If the value\n",
    "            is a path to a file, the file must be a CSV. Only note accessions\n",
    "            in this file will be used. If the value is not a valid file path,\n",
    "            all available note accs will be used, i.e. the model will be\n",
    "            trained on the whole dataset.\"\"\"\n",
    "        self.setname = setname\n",
    "        self.define_subsets_list()\n",
    "        self.label_type_ld = label_type_ld\n",
    "        self.label_meanings = label_meanings\n",
    "        self.num_channels = num_channels\n",
    "        self.pixel_bounds = pixel_bounds\n",
    "        if self.setname == 'train':\n",
    "            self.data_augment = data_augment\n",
    "        else:\n",
    "            self.data_augment = False\n",
    "        print('For dataset',self.setname,'data_augment is',self.data_augment)\n",
    "        self.crop_type = crop_type\n",
    "        assert self.crop_type == 'single'\n",
    "        self.selected_note_acc_files = selected_note_acc_files\n",
    "        \n",
    "        #Define location of the CT volumes\n",
    "        self.main_clean_path = DR176_CT_PATH\n",
    "        self.volume_log_df = pd.read_csv('./load_dataset/fakedata/CT_Scan_Preprocessing_Log_File_FINAL_SMALL.csv',header=0,index_col=0)\n",
    "        \n",
    "        #Get the example ids\n",
    "        self.volume_accessions = self.get_volume_accessions()\n",
    "                        \n",
    "        #Get the ground truth labels\n",
    "        self.labels_df = self.get_labels_df()\n",
    "    \n",
    "    # Pytorch Required Methods #------------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.volume_accessions)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return a single sample at index <idx>. The sample is a Python\n",
    "        dictionary with keys 'data' and 'gr_truth' for the image and label,\n",
    "        respectively\"\"\"\n",
    "        return self._get_pace(self.volume_accessions[idx])\n",
    "    \n",
    "    # Volume Accession Methods #------------------------------------------------\n",
    "    def get_note_accessions(self):\n",
    "        setname_file = self.selected_note_acc_files[self.setname]\n",
    "        if os.path.isfile(setname_file):\n",
    "            print('\\tObtaining note accessions from',setname_file)\n",
    "            sel_accs = pd.read_csv(setname_file,header=0)            \n",
    "            assert sorted(list(set(sel_accs['Subset_Assigned'].values.tolist())))==sorted(self.subsets_list)\n",
    "            note_accs = sel_accs.loc[:,'Accession'].values.tolist()\n",
    "            print('\\tTotal theoretical note accessions in subsets:',len(note_accs))\n",
    "            return note_accs\n",
    "        else: \n",
    "            print('\\tObtaining note accessions from complete identifiers file')\n",
    "            #Read in identifiers file, which contains note_accessions\n",
    "            #Columns are MRN, Accession, Set_Assigned, Set_Should_Be, Subset_Assigned\n",
    "            all_ids = pd.read_csv('./load_dataset/fakedata/all_identifiers.csv',header=0)\n",
    "           \n",
    "            #Extract the note_accessions\n",
    "            note_accs = []\n",
    "            for subset in self.subsets_list: #e.g. ['imgvalid_a','imgvalid_b']\n",
    "                subset_note_accs = all_ids[all_ids['Subset_Assigned']==subset].loc[:,'Accession'].values.tolist()\n",
    "                note_accs += subset_note_accs\n",
    "            print('\\tTotal theoretical note accessions in subsets:',len(note_accs))\n",
    "            return note_accs\n",
    "    \n",
    "    def get_volume_accessions(self):\n",
    "        note_accs = self.get_note_accessions()\n",
    "        #Translate note_accessions to volume_accessions based on what data has been\n",
    "        #preprocessed successfully. volume_log_df has note accessions as the\n",
    "        #index, and the column 'full_filename_npz' for the volume accession.\n",
    "        #The column 'status' should equal 'success' if the volume has been\n",
    "        #preprocessed correctly.\n",
    "        print('\\tTotal theoretical volumes in whole dataset:',self.volume_log_df.shape[0])\n",
    "        self.volume_log_df = self.volume_log_df[self.volume_log_df['status']=='success']\n",
    "        print('\\tTotal successfully preprocessed volumes in whole dataset:',self.volume_log_df.shape[0])\n",
    "        volume_accs = []\n",
    "        for note_acc in note_accs:\n",
    "            if note_acc in self.volume_log_df.index.values.tolist():\n",
    "                volume_accs.append(self.volume_log_df.at[note_acc,'full_filename_npz'])\n",
    "        print('\\tFinal total successfully preprocessed volumes in requested subsets:',len(volume_accs))\n",
    "        #According to this thread: https://github.com/pytorch/pytorch/issues/13246\n",
    "        #it is better to use a numpy array than a list to reduce memory leaks.\n",
    "        return np.array(volume_accs)\n",
    "    \n",
    "    # Ground Truth Label Methods #----------------------------------------------\n",
    "    def get_labels_df(self):\n",
    "        #Get the ground truth labels based on requested label type.\n",
    "        labels_df = read_in_labels(self.label_type_ld, self.setname)\n",
    "        \n",
    "        #Now filter the ground truth labels based on the desired label meanings:\n",
    "        if self.label_meanings != 'all': #i.e. if you want to filter\n",
    "            labels_df = labels_df[self.label_meanings]\n",
    "        return labels_df\n",
    "    \n",
    "    # Fetch a CT Volume (__getitem__ implementation) #--------------------------\n",
    "    def _get_pace(self, volume_acc):\n",
    "        \"\"\"<volume_acc> is for example RHAA12345_6.npz\"\"\"\n",
    "        #Load compressed npz file: [slices, square, square]\n",
    "        ctvol = np.load(os.path.join(self.main_clean_path, volume_acc))['ct']\n",
    "        \n",
    "        #Prepare the CT volume data (already torch Tensors)\n",
    "        data = prepare_ctvol_2019_10_dataset(ctvol, self.pixel_bounds, self.data_augment, self.num_channels, self.crop_type)\n",
    "        \n",
    "        #Get the ground truth:\n",
    "        note_acc = self.volume_log_df[self.volume_log_df['full_filename_npz']==volume_acc].index.values.tolist()[0]\n",
    "        gr_truth = self.labels_df.loc[note_acc, :].values\n",
    "        gr_truth = torch.from_numpy(gr_truth).squeeze().type(torch.float)\n",
    "        \n",
    "        #When training on only one abnormality you must unsqueeze to prevent\n",
    "        #a dimensions error when training the model:\n",
    "        if len(self.label_meanings)==1:\n",
    "            gr_truth = gr_truth.unsqueeze(0)\n",
    "        \n",
    "        #Create the sample\n",
    "        sample = {'data': data, 'gr_truth': gr_truth, 'volume_acc': volume_acc}\n",
    "        return sample\n",
    "    \n",
    "    # Sanity Check #------------------------------------------------------------\n",
    "    def define_subsets_list(self):\n",
    "        assert self.setname in ['train','valid','test']\n",
    "        if self.setname == 'train':\n",
    "            self.subsets_list = ['imgtrain']\n",
    "        elif self.setname == 'valid':\n",
    "            self.subsets_list = ['imgvalid_a']\n",
    "        elif self.setname == 'test':\n",
    "            self.subsets_list = ['imgtest_a','imgtest_b','imgtest_c','imgtest_d']\n",
    "        print('Creating',self.setname,'dataset with subsets',self.subsets_list)\n",
    "\n",
    "#######################\n",
    "# Ground Truth Labels #---------------------------------------------------------\n",
    "#######################\n",
    "\n",
    "def read_in_labels(label_type_ld, setname):\n",
    "    \"\"\"Return a pandas dataframe with the dataset labels.\n",
    "    Accession numbers are the index and labels (e.g. \"pneumonia\") are the columns.\n",
    "    <setname> can be 'train', 'valid', or 'test'.\"\"\"\n",
    "    assert label_type_ld == 'disease_new'\n",
    "    labels_file = './load_dataset/fakedata/2019-12-18_duke_disease/img'+setname+'_BinaryLabels.csv'\n",
    "    return pd.read_csv(labels_file, header=0, index_col = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "391a2695-d273-4141-b518-f5906285ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb669f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recall(labels_gt, labels_prediction):\n",
    "    \"\"\"\n",
    "    set of ground truth labels and list of prediction lists. \n",
    "    This is an independent of k way to calculate the recall.\n",
    "    \"\"\"\n",
    "    n = len(labels_prediction)\n",
    "    recall = 0\n",
    "    for i in range(n):\n",
    "        recall += len(set(labels_gt) & set(labels_prediction[i]))/len(labels_gt)\n",
    "    return recall/n\n",
    "\n",
    "def get_batch_data(data, index, size):\n",
    "    \"\"\"\n",
    "    For minibatch training\n",
    "    \"\"\"\n",
    "    column_1 = []\n",
    "    column_2 = []\n",
    "    for i in range(index, index + size):\n",
    "        line = data[i]\n",
    "        # anchor image\n",
    "        column_1.append(int(line[0]))\n",
    "        # positive image\n",
    "        column_2.append(int(line[1]))\n",
    "    return np.array(column_1), np.array(column_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cfe49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ConvNextImageProcessor, ResNetForImageClassification, ResNetConfig\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from torchvision import models, utils\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "class CTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CTModel, self).__init__()\n",
    "        \n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*(list(resnet.children())[:-2]))\n",
    "\n",
    "        #conv input torch.Size([1,134,512,14,14])\n",
    "        self.reducingconvs = nn.Sequential(\n",
    "            nn.Conv3d(134, 64, kernel_size = (3,3,3), stride=(3,1,1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(64, 32, kernel_size = (3,3,3), stride=(3,1,1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv3d(32, 16, kernel_size = (3,2,2), stride=(3,2,2), padding=0),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*18*6*6, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128))\n",
    "\n",
    "        def forward(self, x):\n",
    "            shape = list(x.size())\n",
    "            #example shape: [1,134,3,420,420]\n",
    "            #example shape: [2,134,3,420,420]\n",
    "            batch_size = int(shape[0])\n",
    "            x = x.view(batch_size*134,3,512,512)\n",
    "            x = self.features(x)\n",
    "            x = x.view(batch_size,134,512,16,16)\n",
    "            x = self.reducingconvs(x)\n",
    "            #output is shape [batch_size, 16, 18, 6, 6]\n",
    "            x = x.view(batch_size, 16*18*6*6)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(3, 1, 1), padding=0),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential( \n",
    "            nn.Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(3, 1, 1), padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential( \n",
    "            nn.Conv3d(128, 64, kernel_size=(3, 2, 2), stride=(3, 2, 2), padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*6*6, 1024)\n",
    "        )\n",
    "\n",
    "            \n",
    "    def old_forward(self, x):\n",
    "\n",
    "        # ResNet\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        # Convolutions\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3263c2ad-47df-422f-9439-edbe3d0eb543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000, -2.1103,  ..., -2.1365, -2.1140, -2.0976],\n",
      "         [-2.1154, -2.1440, -2.1242,  ..., -2.1486, -2.1064, -2.1364],\n",
      "         [-2.1331, -2.0919, -2.0996,  ..., -2.1276, -2.1228, -2.1061],\n",
      "         ...,\n",
      "         [-2.1036, -2.1358, -2.1417,  ..., -2.1247, -2.0925, -2.1146],\n",
      "         [-2.0729, -2.1120, -2.0932,  ..., -2.1170, -2.1351, -2.1147],\n",
      "         [-2.1249, -2.0949, -2.1047,  ..., -2.1516, -2.1088, -2.1403]],\n",
      "\n",
      "        [[-2.0411, -2.0560, -2.0577,  ..., -2.0542, -2.0417, -2.0401],\n",
      "         [-2.0028, -2.0176, -2.0425,  ..., -2.0406, -2.0270, -2.0252],\n",
      "         [-2.0171, -2.0501, -2.0557,  ..., -2.0297, -2.0359, -2.0082],\n",
      "         ...,\n",
      "         [-2.0195, -2.0319, -2.0438,  ..., -2.0374, -2.0019, -2.0422],\n",
      "         [-2.0233, -2.0393, -2.0251,  ..., -2.0455, -2.0344, -2.0686],\n",
      "         [-2.0587, -2.0272, -2.0577,  ..., -2.0522, -2.0340, -2.0501]],\n",
      "\n",
      "        [[-1.8047, -1.8476, -1.8089,  ..., -1.8045, -1.7889, -1.8189],\n",
      "         [-1.8062, -1.8002, -1.8065,  ..., -1.7973, -1.7645, -1.8298],\n",
      "         [-1.8173, -1.8098, -1.8083,  ..., -1.8047, -1.8057, -1.8112],\n",
      "         ...,\n",
      "         [-1.7728, -1.7749, -1.7983,  ..., -1.8107, -1.7723, -1.7928],\n",
      "         [-1.7868, -1.7891, -1.7858,  ..., -1.7748, -1.8384, -1.7818],\n",
      "         [-1.7803, -1.7951, -1.8063,  ..., -1.8199, -1.8297, -1.7895]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 3, 512, 512])\n",
      "tensor([[[[-2.1352, -2.1290, -2.1381,  ..., -2.1218, -2.1102, -2.1337],\n",
      "          [-2.1073, -2.1397, -2.0868,  ..., -2.1066, -2.1230, -2.1149],\n",
      "          [-2.1146, -2.1448, -2.1160,  ..., -2.1433, -2.1356, -2.0931],\n",
      "          ...,\n",
      "          [-2.1137, -2.1103, -2.1450,  ..., -2.1231, -2.1084, -2.1335],\n",
      "          [-2.1264, -2.1103, -2.1296,  ..., -2.1158, -2.1303, -2.1160],\n",
      "          [-2.1043, -2.0790, -2.1549,  ..., -2.1179, -2.1245, -2.1048]],\n",
      "\n",
      "         [[-2.0154, -2.0281, -2.0363,  ..., -2.0409, -2.0259, -2.0582],\n",
      "          [-2.0391, -2.0130, -2.0482,  ..., -2.0383, -2.0125, -2.0534],\n",
      "          [-2.0205, -2.0275, -2.0314,  ..., -2.0331, -2.0219, -2.0181],\n",
      "          ...,\n",
      "          [-2.0181, -2.0230, -2.0568,  ..., -2.0334, -2.0550, -2.0734],\n",
      "          [-2.0541, -2.0514, -1.9999,  ..., -2.0273, -2.0356, -2.0206],\n",
      "          [-2.0209, -2.0324, -2.0232,  ..., -2.0283, -2.0209, -2.0191]],\n",
      "\n",
      "         [[-1.8161, -1.8269, -1.8324,  ..., -1.7712, -1.8120, -1.7940],\n",
      "          [-1.7868, -1.8161, -1.7984,  ..., -1.8297, -1.8084, -1.8083],\n",
      "          [-1.8285, -1.7954, -1.7863,  ..., -1.7843, -1.7969, -1.7887],\n",
      "          ...,\n",
      "          [-1.8326, -1.8205, -1.8058,  ..., -1.8034, -1.8036, -1.8057],\n",
      "          [-1.8055, -1.8197, -1.7990,  ..., -1.7894, -1.8426, -1.7861],\n",
      "          [-1.7880, -1.7959, -1.8240,  ..., -1.7726, -1.8247, -1.8038]]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m ct_embedding_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m out \u001b[38;5;241m=\u001b[39m ct_embedding_model(x)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[126], line 185\u001b[0m, in \u001b[0;36mCTModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# ResNet\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(x)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# Convolutions\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[126], line 125\u001b[0m, in \u001b[0;36mResNetImagePreprocessor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_img)\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_slice_thrices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_slice_thrices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_img), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessed_slice_thrices\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "ct_embedding_model = CTModel()\n",
    "x = torch.randn(1, 384, 512, 512)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "ct_embedding_model.to(device)\n",
    "x = x.to(device)\n",
    "\n",
    "out = ct_embedding_model(x)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "722060c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c281cab3-a86a-428b-9ccb-307f515c182a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, random_split, RandomSampler, BatchSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class TripletModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        mode='HN',\n",
    "        seed=42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        mode: (negative sampling) \"random\" or \"HN\"\n",
    "        estimator: \"Linear\" or \"net\"\n",
    "        \"\"\"\n",
    "\n",
    "        # dim latent space\n",
    "        #self.factor = factor \n",
    "\n",
    "        #VSE++\n",
    "        #self.batch_size = 30  \n",
    "\n",
    "        #ResNet18\n",
    "        self.batch_size = 8\n",
    "\n",
    "        #VSE++\n",
    "        #self.epochs = 30\n",
    "\n",
    "        # ResNet18\n",
    "        self.epochs = 1\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.device = None\n",
    "        \n",
    "        if not torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            self.model.to(self.device)\n",
    "        \n",
    "        #VSE++\n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=0.0002)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "        # FF net or LINEAR\n",
    "        #self.estimator = estimator\n",
    "        \n",
    "        # Save checkpoints to this path\n",
    "        self.checkpoint_path = TRIPLET_MODELS_PATH\n",
    "        \n",
    "        # Negative sampling: 'HN' or 'random'\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Triplet loss' alpha\n",
    "        self.alpha = 0.2\n",
    "        \n",
    "        self.seed = seed\n",
    "    \n",
    "    def get_triplets(self, ids_list):\n",
    "        # construct positive pairs and negative-compatibles from the data points in the mini-batch\n",
    "        #print('ids_list:', ids_list)\n",
    "        positive_pairs, negative_compatibles = self.dataset.get_batch_positive_negative_pairs(ids_list)\n",
    "        triplets = list()\n",
    "\n",
    "        if len(positive_pairs) == 0 or len(negative_compatibles) == 0:\n",
    "            logging.warning(f\"Cannot build triplets from current batch! {len(positive_pairs)} positives and {len(negative_compatibles)} negative pair candidates found.\")\n",
    "            return None #skip batch\n",
    "\n",
    "        if self.mode == \"random\":\n",
    "            negative_pairs = [[a, random.choice(negative_compatibles[neg_id])] for (a, neg_id) in negative_compatibles]\n",
    "            # a_p and a_n should always be the same value, so it doesn't matter which one we choose to build the triplet\n",
    "            triplets = torch.tensor([[a_p, p, n] for ([a_p, p], [a_n, n]) in zip(positive_pairs, negative_pairs)])\n",
    "\n",
    "        elif self.mode == \"HN\":\n",
    "            anchors_list = [a for (a, _) in positive_pairs]\n",
    "            #embeddings = self.dataset.get_embeddings(ids_list)\n",
    "            anchors_embs = self.dataset.get_embeddings(anchors_list)\n",
    "            negative_pairs = list()\n",
    "            for anchor_id, anchor_emb in zip(anchors_list, anchors_embs):\n",
    "                negatives_compatibles_ids = negative_compatibles[anchor_id]\n",
    "                n_compatibles = len(negatives_compatibles_ids)\n",
    "                negatives_compatibles_embs = self.dataset.get_embeddings(negatives_compatibles_ids)\n",
    "                negatives_compatibles_embs = negatives_compatibles_embs.squeeze(1)\n",
    "                anchor_emb_repeat = anchor_emb.repeat(n_compatibles, 1)\n",
    "                #anchor_emb_repeat = torch.fill(torch.empty(n_compatibles), anchor_emb)\n",
    "                a_n_pairwise_similarities = torch.nn.functional.cosine_similarity(anchor_emb_repeat, negatives_compatibles_embs)\n",
    "                most_similar_id = torch.argmax(a_n_pairwise_similarities)\n",
    "                negative_pairs.append([anchor_id, negatives_compatibles_ids[most_similar_id]])\n",
    "                #print('\\nSTART ANCHOR\\n')\n",
    "                #print('anchors_list', anchors_list)\n",
    "                #print('anchor_id', anchor_id)\n",
    "                #print('negatives_compatibles_ids', negatives_compatibles_ids)\n",
    "                #print('anchor_emb_repeat', anchor_emb_repeat.shape, anchor_emb_repeat)\n",
    "                #print('negatives_compatibles_embs', negatives_compatibles_embs.shape, negatives_compatibles_embs)\n",
    "                #print('a_n_pairwise_similarities', a_n_pairwise_similarities)\n",
    "                #print('most_similar_id', most_similar_id)\n",
    "                #print('\\nEND ANCHOR\\n')\n",
    "            # a_p and a_n should always be the same value, so it doesn't matter which one we choose to build the triplet\n",
    "            triplets = torch.tensor([[a_p, p, n] for ([a_p, p], [a_n, n]) in zip(positive_pairs, negative_pairs)])\n",
    "        if self.device:\n",
    "            triplets = triplets.to(self.device)\n",
    "        return triplets\n",
    "        \n",
    "        \n",
    "    def training(self, dataset, train_frac=0.6, batch_size=8, epochs=1):\n",
    "        \"\"\"\n",
    "        Training process\n",
    "        \"\"\"\n",
    "        \n",
    "        assert train_frac > 0.0 and 1.0 >= train_frac\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Define the sizes of train, validation, and test sets\n",
    "        train_size = int(train_frac * len(self.dataset))  # percentage of the data for training\n",
    "        val_size = int((1.0 - train_frac)/1 * len(self.dataset)) # half of the remaining for validation\n",
    "        test_size = len(self.dataset) - train_size - val_size  # the rest of the remaining for testing\n",
    "\n",
    "        '''\n",
    "        If necessary, adjust the size of the training set when the sum of \n",
    "        the sizes of the three sets differs from the total dataset size.\n",
    "        '''\n",
    "        size_diff = len(self.dataset) - train_size - val_size - test_size\n",
    "        train_size += size_diff\n",
    "\n",
    "        # Use random_split to split the dataset\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(dataset=self.dataset, lengths=[train_size, val_size, test_size], generator=torch.Generator().manual_seed(self.seed))\n",
    "        \n",
    "        # Create a RandomSampler with a predetermined seed and no replacement\n",
    "        #self.training_sampler = RandomSampler(self.train_dataset, replacement=False, generator=torch.Generator().manual_seed(seed))\n",
    "        self.validation_sampler = RandomSampler(self.val_dataset, replacement=False, generator=torch.Generator().manual_seed(self.seed))\n",
    "        self.test_sampler = RandomSampler(self.test_dataset, replacement=False, generator=torch.Generator().manual_seed(self.seed))\n",
    "\n",
    "        #self.train_batch_sampler = BatchSampler(sampler=self.training_sampler, batch_size=self.batch_size, drop_last=True)\n",
    "        self.val_batch_sampler = BatchSampler(sampler=self.validation_sampler, batch_size=len(self.val_dataset), drop_last=True)\n",
    "        self.test_batch_sampler = BatchSampler(sampler=self.test_sampler, batch_size=len(self.test_dataset), drop_last=True)\n",
    "        \n",
    "        # self.dataset.shape := (number of data points, number of classes)\n",
    "        #self.n_classes = self.dataset.shape[1]\n",
    "\n",
    "        self.recalls = [] # recall 1, 10, 25\n",
    "        self.loss_per_epoch = []\n",
    "        self.step_losses = []\n",
    "        self.val_loss_per_epoch = []\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.tb_writer = SummaryWriter(os.path.join(TRIPLET_MODELS_PATH, \"runs\", \"ct_retrieval_trainer_{}\".format(timestamp)))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            logging.info(f\"\\n--------------------------------\\nEpoch {epoch+1} of {self.epochs}\\n--------------------------------\\n\")\n",
    "\n",
    "            batch_counter = 0 # counter of processed batches across training\n",
    "            \n",
    "            epoch_losses = list()\n",
    "            \n",
    "            # change the random seed and reconstruct training_sampler and train_batch_sampler at each epoch\n",
    "            # this way we can assemble never-before-seen triplets to train on.\n",
    "            self.training_sampler = RandomSampler(self.train_dataset, replacement=False, generator=torch.Generator().manual_seed(self.seed + epoch))\n",
    "            self.train_batch_sampler = BatchSampler(sampler=self.training_sampler, batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "            # recalculate dataset embeddings at this epoch\n",
    "            dataset_embeddings = self.dataset.get_updated_embeddings(self.model, self.device)\n",
    "            \n",
    "            for batch_index, training_batch in enumerate(self.train_batch_sampler):\n",
    "                batch_counter += 1\n",
    "                logging.info(f\"=> Batch {batch_counter}:\")\n",
    "\n",
    "                # load batch data\n",
    "                dataset_batch_ids, batch_embeddings, batch_labels = self.train_dataset[training_batch]\n",
    "\n",
    "                batch_id_map = dict((i, j) for (i, j) in zip(dataset_batch_ids.tolist(), training_batch))\n",
    "\n",
    "                # dataset_batch_ids != training_batch bacause dataset_batch_ids corresponds to the original\n",
    "                # unsplitted dataset while training_batch maps to the training dataset\n",
    "\n",
    "                if self.device is not None:\n",
    "                    batch_embeddings = batch_embeddings.to(self.device)\n",
    "                    \n",
    "                batch_triplets = self.get_triplets(dataset_batch_ids.tolist())\n",
    "                batch_triplets = [[batch_id_map[a], batch_id_map[p], batch_id_map[n]] for [a, p, n] in batch_triplets.tolist()]\n",
    "                batch_triplets = torch.tensor(batch_triplets)\n",
    "                #print('training_batch:', training_batch)\n",
    "                #print('dataset_batch_ids:', dataset_batch_ids)\n",
    "                #print('batch_triplets:', batch_triplets)\n",
    "                \n",
    "                if batch_triplets is None:\n",
    "                    # skip empty batch\n",
    "                    continue\n",
    "                \n",
    "                # perform forward pass over all samples in the batch\n",
    "                self.model.train(True)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(batch_embeddings)\n",
    "\n",
    "                # map the dataset IDs referenced in the triplets to the indices in the batched model output\n",
    "                #print('batch_ids:', mini_batch)\n",
    "                #print('triplets before mapping:\\n', triplets)\n",
    "                #triplets = self._map_triplets(mini_batch, triplets)\n",
    "                #print('triplets after mapping:\\n', triplets)\n",
    "                \n",
    "                # calculate loss and gradients\n",
    "                # IMPORTANT: the loss is calculated for each triplet (3-tuples of samples), therefore,\n",
    "                # if there is a sample which is not part of a triplet, then it will not be needed in\n",
    "                # calculation.\n",
    "                batch_loss = self.loss(outputs, training_batch, batch_triplets, alpha=self.alpha)\n",
    "                batch_loss.requires_grad = True\n",
    "                batch_loss.backward()\n",
    "\n",
    "                # update model weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                self.tb_writer.add_scalar('Steps: Loss/train', batch_loss, global_step=batch_counter)\n",
    "                \n",
    "                epoch_losses.append(batch_loss)\n",
    "                self.step_losses.append(batch_loss)\n",
    "                logging.info(f\"Batch {batch_counter} loss: {round(batch_loss.item(), 4)}\")\n",
    "            \n",
    "            # finished iterating the batches\n",
    "            epoch_mean_loss = (sum(epoch_losses) / len(epoch_losses)).item()\n",
    "            self.tb_writer.add_scalar('Epochs: Loss/train', epoch_mean_loss, global_step=epoch+1)\n",
    "            self.loss_per_epoch.append(epoch_mean_loss)\n",
    "\n",
    "            logging.info(f'Training loss: {round(epoch_mean_loss, 4)}')\n",
    "            \n",
    "            \n",
    "            # evaluate on validation set\n",
    "            logging.info(\"Evaluating...\")\n",
    "            self.model.eval()\n",
    "            val_epoch_losses = list()\n",
    "            with torch.no_grad():\n",
    "                for val_batch_index, val_batch in enumerate(self.val_batch_sampler):\n",
    "\n",
    "                    val_batch_ids, val_batch_embeddings, val_batch_labels = self.val_dataset[val_batch]\n",
    "\n",
    "                    val_batch_id_map = dict((i, j) for (i, j) in zip(val_batch_ids.tolist(), val_batch))\n",
    "                    \n",
    "\n",
    "                    if self.device is not None:\n",
    "                        val_batch_embeddings = val_batch_embeddings.to(self.device)\n",
    "                        \n",
    "                    val_batch_triplets = self.get_triplets(val_batch_ids.tolist())\n",
    "                    val_batch_triplets = [[val_batch_id_map[a], val_batch_id_map[p], val_batch_id_map[n]] for [a, p, n] in val_batch_triplets.tolist()]\n",
    "                    val_batch_triplets = torch.tensor(val_batch_triplets)\n",
    "                    \n",
    "                    if val_batch_triplets is None:\n",
    "                        # skip validation if there was no triplets to evaluate\n",
    "                        continue\n",
    "\n",
    "                    # map the dataset IDs referenced in the triplets to the indices in the batched model output\n",
    "\n",
    "                    #val_triplets = self._map_triplets(val_batch, val_triplets)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # perform evaluation on validation data\n",
    "                    val_outputs = self.model(val_batch_embeddings)\n",
    "\n",
    "                    # calculate validation loss\n",
    "                    val_batch_loss = self.loss(val_outputs, val_batch, val_batch_triplets, alpha=self.alpha)\n",
    "                    val_epoch_losses.append(val_batch_loss)\n",
    "                    logging.info(f\"Validation batch {val_batch_index+1} loss: {round(val_batch_loss.item(), 4)}\")\n",
    "                \n",
    "                # finished iterating the batches\n",
    "                val_mean_loss = (sum(val_epoch_losses) / len(val_epoch_losses)).item()\n",
    "                self.tb_writer.add_scalars(\n",
    "                    'Training vs. Validation Loss',\n",
    "                    {\n",
    "                        'Training': epoch_mean_loss, \n",
    "                        'Validation': val_mean_loss,\n",
    "                    }, \n",
    "                    epoch + 1\n",
    "                )\n",
    "                self.val_loss_per_epoch.append(val_mean_loss)\n",
    "\n",
    "                logging.info(f'Validation loss: {round(val_mean_loss, 4)}')\n",
    "            \n",
    "                # end batch iteration\n",
    "            logging.info(\"Done evaluating.\")\n",
    "            if(self.val_loss_per_epoch[-1] == min(self.val_loss_per_epoch)):\n",
    "                logging.info(\"Best validation loss achieved! Saving checkpoint...\")\n",
    "                self.save(\n",
    "                    epoch,\n",
    "                    self.loss_per_epoch, \n",
    "                    self.step_losses, \n",
    "                    self.val_loss_per_epoch, \n",
    "                    self.recalls,\n",
    "                    time.time()-start_time,\n",
    "                    os.path.join(TRIPLET_CHECKPOINTS_PATH, f'ct_retrieval_trainer_{timestamp}.pth'),\n",
    "                )\n",
    "                logging.info(\"Checkpoint saved.\")\n",
    "\n",
    "            # update optimizer scheduler ater completing an epoch\n",
    "            self.scheduler.step()\n",
    "            # end epoch iteration\n",
    "        #print('train_dataset:', self.train_dataset[0:len(self.train_dataset)][0])\n",
    "        #print('val_dataset:', self.val_dataset[0:len(self.val_dataset)][0])\n",
    "\n",
    "    def _map_triplets(self, batch_ids, triplets):\n",
    "        a_tensor = triplets.select(1, 0)\n",
    "        p_tensor = triplets.select(1, 1)\n",
    "        n_tensor = triplets.select(1, 2)\n",
    "        a_items = [e.item() for e in a_tensor]\n",
    "        p_items = [e.item() for e in p_tensor]\n",
    "        n_items = [e.item() for e in n_tensor]\n",
    "        a_index = list()\n",
    "        p_index = list()\n",
    "        n_index = list()\n",
    "        for (a, p, n) in zip(a_items, p_items, n_items):\n",
    "            a_index.append(batch_ids.index(a))\n",
    "            p_index.append(batch_ids.index(p))\n",
    "            n_index.append(batch_ids.index(n))\n",
    "        mapped_triplets = torch.tensor([a_index, p_index, n_index])\n",
    "        mapped_triplets = mapped_triplets.transpose(0, 1)\n",
    "        return mapped_triplets\n",
    "\n",
    "    def _max(self, a, b):\n",
    "        if a > b:\n",
    "            return a\n",
    "        return b\n",
    "    \n",
    "    def loss(self, embeddings, embeddings_ids, triplets_ids, alpha=0.2):\n",
    "        \n",
    "        \"\"\"\n",
    "        for computing the triplet loss [alpha + negative_similarity - positive_similarity]_{+}\n",
    "        \"\"\"\n",
    "        anchors_ids = torch.select(triplets_ids, 1, 0).tolist()\n",
    "        positives_ids = torch.select(triplets_ids, 1, 1).tolist()\n",
    "        negatives_ids = torch.select(triplets_ids, 1, 2).tolist()\n",
    "\n",
    "        ids_map = dict((j, i) for i, j in enumerate(embeddings_ids))\n",
    "        \n",
    "        anchors = embeddings[[ids_map[a] for a in anchors_ids]]\n",
    "        positives = embeddings[[ids_map[p] for p in positives_ids]]\n",
    "        negatives = embeddings[[ids_map[n] for n in negatives_ids]]\n",
    "        \n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        \n",
    "        positive_similarities = cos(anchors, positives)\n",
    "        negative_similarities = cos(anchors, negatives)\n",
    "        \n",
    "        unrectified_batch_loss = alpha + negative_similarities - positive_similarities\n",
    "        rectified_batch_loss = unrectified_batch_loss.detach().map_(torch.zeros(len(unrectified_batch_loss)), self._max)\n",
    "        #rectified_batch_loss = torch.func.vmap(torch.max)(unrectified_batch_loss, torch.tensor(0))\n",
    "        batch_loss = torch.mean(rectified_batch_loss)\n",
    "        if self.device:\n",
    "            batch_loss = batch_loss.to(device)\n",
    "        return batch_loss\n",
    "    \n",
    "    def save(self, epoch, epoch_loss, step_loss, val_loss, recalls, running_time, directory):\n",
    "        \"\"\"\n",
    "        For saving logs of the experiment\n",
    "        \"\"\"\n",
    "        \n",
    "        torch.save(\n",
    "            {\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.scheduler.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'epoch_loss': epoch_loss,\n",
    "                'step_loss': step_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'recalls': recalls,\n",
    "                'running_time': running_time,\n",
    "            },\n",
    "            directory\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cf07a1b-3d4a-4b6c-ba0b-e176912bd55f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n        def predict(self,query,split):\\n        \"\"\"\\n        the split defines where we are going to search\\n        \"\"\"\\n        if type(query) is not list:\\n            query= [query]\\n\\n        i_input = self.visual_encoder(tf.nn.embedding_lookup(visual_matrix, query))\\n        if split==\"val\":\\n                c_eval= self.visual_encoder(visual_matrix[self.val_ids])\\n        if split==\"test\":\\n                c_eval= self.visual_encoder(visual_matrix[self.test_ids])\\n        if split==\"train\":\\n                c_eval=self.visual_encoder(visual_matrix[self.train_ids])\\n\\n        rating= tf.matmul(i_input, tf.transpose(c_eval) )\\n        return np.reshape(rating, [-1])\\n\\n    def metric(self, split, k=10):\\n        \"\"\"\\n        to compute metrics\\n        \"\"\"\\n        if split == \"val\":\\n            ids, gt = self.val_ids, self.labels_val\\n        if split == \"test\":\\n            ids, gt = self.test_ids, self.labels_test\\n\\n        metric=0\\n\\n        for i in range(len(ids)): #querys\\n            top= np.argsort(self.predict(ids[i],split))[::-1][1:k+1] #first one must be the query\\n            #get labels\\n            prediction= [gt[j] for j in top]\\n            metric+=recall(gt[i], prediction)\\n        return metric/len(ids) #average\\n\\n    def inference(self):\\n        \"\"\"\\n        testing phase\\n        \"\"\"\\n        results=(self.metric(\"test\",k=1), self.metric(\"test\",k=10), self.metric(\"test\",k=25))\\n        print(results)\\n        np.save(self.DIS_MODEL_FILE+\"test_metrics.npy\", np.array([results], dtype=object) )\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    \n",
    "        def predict(self,query,split):\n",
    "        \"\"\"\n",
    "        the split defines where we are going to search\n",
    "        \"\"\"\n",
    "        if type(query) is not list:\n",
    "            query= [query]\n",
    "\n",
    "        i_input = self.visual_encoder(tf.nn.embedding_lookup(visual_matrix, query))\n",
    "        if split==\"val\":\n",
    "                c_eval= self.visual_encoder(visual_matrix[self.val_ids])\n",
    "        if split==\"test\":\n",
    "                c_eval= self.visual_encoder(visual_matrix[self.test_ids])\n",
    "        if split==\"train\":\n",
    "                c_eval=self.visual_encoder(visual_matrix[self.train_ids])\n",
    "\n",
    "        rating= tf.matmul(i_input, tf.transpose(c_eval) )\n",
    "        return np.reshape(rating, [-1])\n",
    "\n",
    "    def metric(self, split, k=10):\n",
    "        \"\"\"\n",
    "        to compute metrics\n",
    "        \"\"\"\n",
    "        if split == \"val\":\n",
    "            ids, gt = self.val_ids, self.labels_val\n",
    "        if split == \"test\":\n",
    "            ids, gt = self.test_ids, self.labels_test\n",
    "\n",
    "        metric=0\n",
    "\n",
    "        for i in range(len(ids)): #querys\n",
    "            top= np.argsort(self.predict(ids[i],split))[::-1][1:k+1] #first one must be the query\n",
    "            #get labels\n",
    "            prediction= [gt[j] for j in top]\n",
    "            metric+=recall(gt[i], prediction)\n",
    "        return metric/len(ids) #average\n",
    "\n",
    "    def inference(self):\n",
    "        \"\"\"\n",
    "        testing phase\n",
    "        \"\"\"\n",
    "        results=(self.metric(\"test\",k=1), self.metric(\"test\",k=10), self.metric(\"test\",k=25))\n",
    "        print(results)\n",
    "        np.save(self.DIS_MODEL_FILE+\"test_metrics.npy\", np.array([results], dtype=object) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a6feaeb-6e3d-4a71-a31c-48658b26116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data point with dataset_id=7 will be discarded because its corresponding visual embedding file does not exist: C:\\Users\\User\\Documents\\Proyecto Proximity\\DR70\\visual_embeddings\\resnet18\\reshaped_averaged\\1.3.12.2.1107.5.1.4.83504.30000020021012090131800045301.npy\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 1 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [67, 47, 18, 55, 39, 12, 45, 28]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2585\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [50, 48, 53, 62, 15, 44, 19, 11]\n",
      "INFO:root:Batch 2 loss: 0.2311\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [25, 34, 56, 6, 41, 31, 21, 61]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 56 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2167\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [43, 3, 42, 35, 68, 32, 30, 23]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2619\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [9, 4, 0, 60, 49, 57, 40, 8]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.206\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [26, 14, 17, 65, 63, 51, 16, 58]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 63 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 58 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2372\n",
      "INFO:root:Training loss: 0.2352\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [29, 5, 22, 46, 66, 27, 10, 52, 7, 13, 37, 38, 20, 54, 59, 33, 2, 64, 1, 36]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2243\n",
      "INFO:root:Validation loss: 0.2243\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:Best validation loss achieved! Saving checkpoint...\n",
      "INFO:root:Checkpoint saved.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 2 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [60, 47, 42, 58, 44, 43, 65, 49]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 58 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2324\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [61, 14, 8, 16, 21, 35, 41, 40]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2351\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [25, 68, 39, 0, 32, 63, 11, 6]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.242\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [28, 55, 57, 30, 4, 19, 51, 53]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 28 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2376\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [23, 18, 31, 26, 15, 45, 3, 17]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 18 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.2126\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [48, 62, 67, 9, 12, 50, 56, 34]\n",
      "INFO:root:Batch 6 loss: 0.2\n",
      "INFO:root:Training loss: 0.2266\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [33, 66, 52, 46, 59, 5, 2, 37, 7, 22, 29, 27, 36, 38, 10, 20, 64, 1, 13, 54]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2315\n",
      "INFO:root:Validation loss: 0.2315\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 3 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [60, 6, 42, 61, 9, 45, 49, 55]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 61 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.222\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [25, 67, 23, 48, 18, 34, 40, 4]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 23 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2487\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [15, 35, 63, 68, 50, 3, 53, 65]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 68 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2393\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [56, 16, 14, 17, 51, 21, 19, 41]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 56 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 21 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2228\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [11, 30, 12, 28, 57, 26, 0, 62]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 30 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 28 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.2285\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [8, 43, 47, 39, 58, 31, 32, 44]\n",
      "INFO:root:Batch 6 loss: 0.2375\n",
      "INFO:root:Training loss: 0.2331\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [38, 5, 27, 36, 29, 7, 33, 22, 20, 52, 2, 13, 46, 37, 64, 54, 66, 1, 10, 59]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2316\n",
      "INFO:root:Validation loss: 0.2316\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 4 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [3, 18, 55, 39, 15, 31, 32, 43]\n",
      "INFO:root:Batch 1 loss: 0.2328\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [61, 58, 25, 23, 34, 16, 50, 28]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2106\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [63, 35, 21, 6, 44, 17, 62, 4]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2123\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [49, 26, 60, 56, 42, 0, 30, 45]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 56 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 30 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.1812\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [12, 8, 41, 65, 68, 48, 47, 57]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 68 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 47 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.2086\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [51, 67, 53, 19, 14, 40, 9, 11]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 67 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 53 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.268\n",
      "INFO:root:Training loss: 0.2189\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [27, 2, 52, 38, 13, 37, 29, 33, 59, 46, 10, 5, 64, 36, 54, 1, 66, 20, 22, 7]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2281\n",
      "INFO:root:Validation loss: 0.2281\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 5 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [56, 8, 68, 39, 57, 18, 35, 43]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 39 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2336\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [61, 32, 3, 45, 42, 17, 14, 67]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 61 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2142\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [34, 55, 51, 31, 53, 23, 25, 44]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2049\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [19, 15, 40, 63, 21, 50, 41, 9]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2516\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [60, 16, 62, 6, 30, 58, 48, 47]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 58 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.2357\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [49, 0, 28, 65, 26, 11, 12, 4]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 28 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2244\n",
      "INFO:root:Training loss: 0.2274\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [1, 52, 5, 27, 38, 22, 7, 10, 66, 13, 59, 29, 37, 20, 2, 64, 46, 36, 54, 33]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2337\n",
      "INFO:root:Validation loss: 0.2337\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 6 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [55, 16, 42, 34, 68, 18, 65, 58]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2285\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [3, 62, 12, 53, 41, 61, 26, 50]\n",
      "INFO:root:Batch 2 loss: 0.2197\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [35, 56, 11, 28, 0, 39, 60, 40]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 39 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2461\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [63, 67, 49, 4, 44, 57, 43, 6]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 67 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2092\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [25, 30, 17, 23, 8, 45, 51, 19]\n",
      "INFO:root:Batch 5 loss: 0.2485\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [15, 14, 31, 48, 21, 32, 47, 9]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 32 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2334\n",
      "INFO:root:Training loss: 0.2309\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [29, 64, 5, 1, 22, 37, 36, 54, 33, 66, 38, 2, 52, 13, 20, 10, 59, 7, 27, 46]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2222\n",
      "INFO:root:Validation loss: 0.2222\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:Best validation loss achieved! Saving checkpoint...\n",
      "INFO:root:Checkpoint saved.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 7 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [17, 0, 16, 60, 32, 49, 45, 6]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 32 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.1923\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [57, 26, 68, 39, 55, 51, 12, 21]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 68 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2368\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [34, 35, 15, 14, 53, 25, 41, 30]\n",
      "INFO:root:Batch 3 loss: 0.2262\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [61, 4, 67, 56, 63, 40, 3, 44]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2253\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [58, 8, 31, 18, 9, 47, 62, 28]\n",
      "INFO:root:Batch 5 loss: 0.2339\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [11, 23, 43, 65, 42, 48, 19, 50]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 23 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2215\n",
      "INFO:root:Training loss: 0.2227\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [10, 29, 54, 37, 46, 5, 66, 33, 36, 38, 27, 7, 59, 1, 13, 20, 22, 64, 52, 2]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.235\n",
      "INFO:root:Validation loss: 0.235\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 8 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [30, 31, 40, 12, 35, 44, 39, 14]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2658\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [41, 60, 67, 57, 61, 21, 49, 19]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 67 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2415\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [47, 34, 58, 65, 45, 32, 48, 55]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 47 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2223\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [6, 23, 25, 18, 17, 16, 26, 42]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 23 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 25 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 18 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2345\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [4, 51, 9, 68, 8, 56, 50, 11]\n",
      "INFO:root:Batch 5 loss: 0.2413\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [53, 28, 0, 63, 62, 15, 3, 43]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 28 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2206\n",
      "INFO:root:Training loss: 0.2377\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [38, 52, 27, 10, 36, 37, 59, 13, 64, 1, 5, 29, 33, 20, 46, 2, 54, 22, 7, 66]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2277\n",
      "INFO:root:Validation loss: 0.2277\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 9 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [47, 31, 44, 60, 41, 11, 45, 0]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 45 in this batch. Skipping...\n",
      "INFO:root:Batch 1 loss: 0.2328\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [32, 67, 50, 8, 58, 9, 34, 26]\n",
      "INFO:root:Batch 2 loss: 0.2394\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [19, 25, 35, 39, 55, 12, 15, 42]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 39 in this batch. Skipping...\n",
      "INFO:root:Batch 3 loss: 0.2209\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [21, 14, 53, 61, 4, 48, 16, 40]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.244\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [63, 68, 65, 43, 3, 62, 18, 56]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 63 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.1946\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [30, 57, 23, 6, 17, 28, 49, 51]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 28 in this batch. Skipping...\n",
      "INFO:root:Batch 6 loss: 0.2254\n",
      "INFO:root:Training loss: 0.2262\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [66, 38, 13, 46, 2, 59, 54, 36, 52, 29, 22, 10, 5, 37, 27, 1, 64, 33, 20, 7]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2376\n",
      "INFO:root:Validation loss: 0.2376\n",
      "INFO:root:Done evaluating.\n",
      "INFO:root:\n",
      "--------------------------------\n",
      "Epoch 10 of 10\n",
      "--------------------------------\n",
      "\n",
      "INFO:root:=> Batch 1:\n",
      "INFO:root:Generating triplets for batch [45, 9, 34, 25, 31, 30, 12, 44]\n",
      "INFO:root:Batch 1 loss: 0.233\n",
      "INFO:root:=> Batch 2:\n",
      "INFO:root:Generating triplets for batch [23, 15, 48, 51, 35, 49, 42, 40]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 23 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 35 in this batch. Skipping...\n",
      "INFO:root:Could not construct a positive pair for anchor ID 40 in this batch. Skipping...\n",
      "INFO:root:Batch 2 loss: 0.2459\n",
      "INFO:root:=> Batch 3:\n",
      "INFO:root:Generating triplets for batch [39, 60, 17, 21, 16, 62, 53, 50]\n",
      "INFO:root:Batch 3 loss: 0.2246\n",
      "INFO:root:=> Batch 4:\n",
      "INFO:root:Generating triplets for batch [67, 6, 26, 47, 11, 8, 56, 3]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 47 in this batch. Skipping...\n",
      "INFO:root:Batch 4 loss: 0.2295\n",
      "INFO:root:=> Batch 5:\n",
      "INFO:root:Generating triplets for batch [0, 28, 14, 43, 41, 57, 65, 18]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 65 in this batch. Skipping...\n",
      "INFO:root:Batch 5 loss: 0.2204\n",
      "INFO:root:=> Batch 6:\n",
      "INFO:root:Generating triplets for batch [58, 19, 4, 32, 61, 68, 63, 55]\n",
      "INFO:root:Batch 6 loss: 0.2353\n",
      "INFO:root:Training loss: 0.2314\n",
      "INFO:root:Evaluating...\n",
      "INFO:root:Generating triplets for batch [22, 59, 10, 13, 7, 52, 36, 2, 20, 38, 1, 33, 37, 27, 64, 66, 46, 29, 5, 54]\n",
      "INFO:root:Could not construct a positive pair for anchor ID 1 in this batch. Skipping...\n",
      "INFO:root:Validation batch 1 loss: 0.2402\n",
      "INFO:root:Validation loss: 0.2402\n",
      "INFO:root:Done evaluating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: tensor([39, 32, 18, 61, 60, 12, 67, 55, 15, 62, 14,  3, 53, 31,  4, 19, 47, 44,\n",
      "        21, 25, 49, 41, 23, 26, 68, 58, 30, 42,  6, 48, 57, 16, 17,  8, 28, 43,\n",
      "        65, 11, 50,  0, 40, 63, 35,  9, 51, 56, 45, 34])\n",
      "val_dataset: tensor([10, 66, 29, 38, 52, 64,  7, 20, 37, 36, 27, 13, 33, 59,  5, 46,  1, 54,\n",
      "        22,  2])\n"
     ]
    }
   ],
   "source": [
    "ct_embedding_model = CTModel()\n",
    "triplet_model = TripletModel(model=ct_embedding_model, mode='HN', seed=42)\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dr70_dataset = CustomDataset(CT_RESNET18_EMBEDDINGS_PATH, DR70_LABELS_PATH)\n",
    "\n",
    "triplet_model.training(dataset=dr70_dataset, train_frac=0.7, batch_size=8, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff008680-37dc-47d7-b93f-0213fbdb4be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7830b3-ed39-4e23-afd5-f0d5b1a7fa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
