{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZsnlTYtdfgo"
   },
   "source": [
    "Algo a definir es si la tarea será de CBIR uni o multi etiqueta. Ello definirá la métrica de evaluación (test y validación) y el monitoreo. Potencialmente ese punto también cambia la forma en que selecciona el positivo y el negativo.\n",
    "\n",
    "En caso multi etiqueta lo común es valorar más una recuperación que comparta todas las etiquetas, por lo que el positivo debe ser así (si no existe tal positivo se selecciona uno que tenga al menos una en comun), y el complemento para definir el negativo sería aquel que no tenga ninguna etiqueta en común.\n",
    "Aquí implementaré dicha estrategia y además el caso en que el negativo es hard negative en minibatch (por definición previa, entonces el requerimiento para ser negative es no tener nada en común).\n",
    "\n",
    "Esta estrategia es mejorable, considerando propiedades del espacio latente para la seleccion más informativa y diversa del ancla, positivo y negativo [1].\n",
    "\n",
    "\n",
    "REFERENCES:\n",
    "\n",
    "  - [1]: https://arxiv.org/abs/2105.03647\n",
    "  - [VSE++]: https://github.com/fartashf/vsepp.git (method of cross modal triplet loss with hard negative mining and definition of hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcvLOs3ohtMB"
   },
   "source": [
    "# Descipción del método\n",
    "\n",
    "Para una tarea de recuperación imagen-imagen, consideremos $N$ imágenes con su asociada multi-etiqueta como data de entrenamiento, y sea $p_{data}$ su distribución. Por definición un par de imagenes que tienen las mismas etiquetas conforman un par positivo, y en otro caso se llaman negativos.\n",
    "\n",
    "En este escenario, el aprendizaje por tripletas formaliza la intuición que la similaridad entre un par positivo $(i_n, {i_n}_{+})$ debería ser mayor que la similaridad entre un par negativo $(i_n, {i_n}_{-})$.\n",
    "\n",
    "$$\\mathcal{L}_{i2i}:= [ \\alpha + s(i_n, {i_n}_{-}) - s(i_n, {i_n}_{+})    ]_{+} ,$$\n",
    "donde $[x]_{+}=max(0,x)$. Aquí $\\alpha$ es un hiperparametro conocido como margen. La similaridad $s$ se calcula como el producto punto $s(i,c)= f(i)^t f(c)$ entre las representaciones normalizadas asignada a las imagenes $f$. El encoder visual es $f(i_n)= E g_{i_n}$, donde $g_{i_n} \\in \\mathbb{R}^{n_V}$ es el vector de características asociado con la imagen $i_n$. Si utilizamos redes neuronales preentrenadas para obtener estos vectores de características, entonces los parámetros entrenables $\\theta$ son las matrices de proyección $E_{\\phi} \\in \\mathbb{R}^{k \\times n_V}$, con $k$ el hiperparametro que define la dimensión del espacio latente.\n",
    "\n",
    "El ajuste de los parámetros entrenables se logra a través del algoritmo del gradiente descendiente estocástico aplicado al problema de optimización de minimizar el valor esperado de la loss. En la práctica, el valor esperado es aproximado muestreando desde la data de entrenamiento (pares positivos). Un enfoque simple es considerar también el muestreo aleatorio de los negativos. Sin embargo, es bien conocido que una mejor técnica es la de hard negative mining, donde los negativos son escogidos dinámicamente de acuerdo al estado del modelo actual [VSE++,1]. Lo que significa que se toman como negativos los casos que son más problemáticos dentro del minibatch de optimización:\n",
    "\n",
    "$$ {i_n}_{-}= \\underset{x \\neq i_n}{ argmax } \\hspace{0.1 cm} s(x,i_n) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JeI8oUBRdcq",
    "outputId": "069a5b43-ffe4-4023-96cb-753c74df89a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "#I programmed this in tensorflow 2.x (e.g 2.13)\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjJ63UBhLd6j"
   },
   "outputs": [],
   "source": [
    "# DATA SIMULATION\n",
    "data= range(1000) #list of img_ids\n",
    "n_labels=6\n",
    "#list of labels in order w/r data list\n",
    "multiplicity_labels=np.random.choice([1,2,3],1000)\n",
    "labels=[]\n",
    "for i in range(1000):\n",
    "  labels.append(list(np.random.choice(list(range(n_labels)),multiplicity_labels[i], replace=False)))\n",
    "#splits\n",
    "Train_img, Train_labels= data[:800], labels[:800]\n",
    "Val_img, Val_labels= data[800:900], labels[800:900]\n",
    "Test_img, Test_labels= data[900:], labels[900:]\n",
    "#visual feautures\n",
    "visual_matrix=np.random.rand(1000, 1024)\n",
    "path= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh3hAQVOSwUU"
   },
   "outputs": [],
   "source": [
    "def recall(labels_gt, labels_prediction):\n",
    "  \"\"\"\n",
    "  set of ground truth labels and list of prediction lists. This is an independent of k way to calculate the recall.\n",
    "  \"\"\"\n",
    "  n= len(labels_prediction)\n",
    "  recall=0\n",
    "  for i in range(n):\n",
    "    recall+= len(set(labels_gt)&set(labels_prediction[i]))/len(labels_gt)\n",
    "  return recall/n\n",
    "\n",
    "def get_batch_data(data, index, size):\n",
    "    \"\"\"\n",
    "    For minibatch training\n",
    "    \"\"\"\n",
    "\n",
    "    column_1 = []\n",
    "    column_2 = []\n",
    "    for i in range(index, index + size):\n",
    "        line = data[i]\n",
    "        column_1.append(int(line[0]))#imgA\n",
    "        column_2.append(int(line[1]))#imgP\n",
    "    return np.array(column_1), np.array(column_2)\n",
    "\n",
    "\n",
    "class triplet_model(object):\n",
    "        def __init__(self, data, labels, visual_matrix,factor,mode,estimator ,pretrain=False):\n",
    "            \"\"\"\n",
    "            mode: (negative sampling) \"random\" or \"HN\"\n",
    "            estimator: \"Linear\" or \"net\"\n",
    "            \"\"\"\n",
    "            self.factor= factor #dim latent space\n",
    "            self.batch_size =  30  #VSE++\n",
    "            self.epochs = 30 #30 #VSE++\n",
    "            self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002) #VSE++\n",
    "            self.estimator=estimator # FF net or LINEAR\n",
    "            self.DIS_MODEL_FILE= path+\"/\"+self.estimator+\"_\" #name path to save\n",
    "            print(self.DIS_MODEL_FILE)\n",
    "            self.mode= mode  #negative sampling: HN or Random\n",
    "            self.alpha=0.2 # in the hinge loss\n",
    "\n",
    "            #get partition for Train, Val and Test from data\n",
    "            self.n_labels= n_labels\n",
    "            self.train_ids,self.labels_train = Train_img, Train_labels\n",
    "            self.val_ids,self.labels_val = Val_img, Val_labels\n",
    "            self.test_ids,self.labels_test = Test_img, Test_labels\n",
    "\n",
    "            #arquitecture FF net\n",
    "            if self.estimator==\"net\":\n",
    "                act= \"relu\"\n",
    "                layer_name = 'Visual_Enconder'\n",
    "                neurons = [visual_matrix.shape[1], int((visual_matrix.shape[1] + self.factor)/2), self.factor]\n",
    "                v_input = tf.keras.Input(shape=(visual_matrix.shape[1],))\n",
    "\n",
    "                v_output = tf.keras.layers.Dense(units=neurons[0], activation=act,  kernel_regularizer='l2' )(v_input)\n",
    "                v_output= tf.keras.layers.Dropout(rate= .2, seed= 0)(v_output)\n",
    "                v_output = tf.keras.layers.Dense(units=neurons[1], activation=act,  kernel_regularizer='l2' )(v_output)\n",
    "                v_output = tf.keras.layers.Dense(units=neurons[2], activation=act,  kernel_regularizer='l2')(v_output)\n",
    "                v_output= tf.math.l2_normalize(v_output, axis=1) #tf.keras.layers.UnitNormalization()(v_output)\n",
    "\n",
    "                self.visual_encoder = tf.keras.Model(inputs=[v_input], outputs=v_output)\n",
    "\n",
    "            if self.estimator==\"Linear\":\n",
    "\n",
    "                layer_name = 'Visual_Enconder'\n",
    "\n",
    "                v_input = tf.keras.Input(shape=(visual_matrix.shape[1],))\n",
    "\n",
    "                v_output = tf.keras.layers.Dense(units=self.factor, use_bias=False )(v_input)\n",
    "                v_output= tf.keras.layers.UnitNormalization()(v_output) #tf.math.l2_normalize(v_output)  #\n",
    "\n",
    "                self.visual_encoder = tf.keras.Model(inputs=[v_input], outputs=v_output)\n",
    "\n",
    "\n",
    "            if pretrain: #To load the model to apply in test\n",
    "                self.visual_encoder= tf.keras.models.load_model(self.DIS_MODEL_FILE+'visual_encoder_tf')\n",
    "                print(\"pre train\")\n",
    "\n",
    "            #place holders\n",
    "            i_input = tf.keras.Input(shape=(visual_matrix.shape[1],), name=\"i\") #anchor\n",
    "            i_n_input = tf.keras.Input(shape=(visual_matrix.shape[1],), name=\"i_n\") #negative\n",
    "            i_p_input = tf.keras.Input(shape=(visual_matrix.shape[1],), name=\"i_p\") #positive\n",
    "            i_emb = self.visual_encoder(i_input)\n",
    "            i_n_emb = self.visual_encoder(i_n_input)\n",
    "            i_p_emb = self.visual_encoder(i_p_input)\n",
    "\n",
    "            sim= ( tf.keras.layers.Dot(axes=1)([i_emb, i_p_emb]),tf.keras.layers.Dot(axes=1)([i_emb, i_n_emb]))\n",
    "            self.model =  tf.keras.Model(inputs=[i_input, i_p_input, i_n_input], outputs=sim)\n",
    "            self.visual_encoder.compile(optimizer=self.optimizer)\n",
    "            self.model.compile(optimizer=self.optimizer)\n",
    "\n",
    "        def loss(self,A, P, N):\n",
    "          \"\"\"\n",
    "          for computing the hinge loss [a+n-P]_{+}\n",
    "          \"\"\"\n",
    "\n",
    "          i_input = tf.nn.embedding_lookup(visual_matrix, A) #[_,1280]\n",
    "          i_n_input = tf.nn.embedding_lookup(visual_matrix, N) #[_,1280]]\n",
    "          i_p_input = tf.nn.embedding_lookup(visual_matrix, P) #[_,1280]]\n",
    "\n",
    "          (positive_pair,negative_pair ) = self.model([i_input, i_p_input, i_n_input])\n",
    "          #print(positive_pair,negative_pair)\n",
    "          i2t_t2i_loss= tf.reduce_mean(tf.maximum(self.alpha - positive_pair+negative_pair, 0) )\n",
    "          return i2t_t2i_loss\n",
    "\n",
    "        def construct_train(self):\n",
    "          \"\"\"\n",
    "          Positive pair selection methodology. It's used just once.\n",
    "          \"\"\"\n",
    "          class_imgs_train= {} # dictionary class: [class]:[list of indices]\n",
    "          for i in range(self.n_labels):\n",
    "            _=[]\n",
    "            c=0\n",
    "            for j in self.labels_train:\n",
    "              if i in j:\n",
    "                _.append(c)\n",
    "              c+=1\n",
    "            class_imgs_train[i]=_\n",
    "\n",
    "          data= [] # construct of positive pairs\n",
    "          for i in self.train_ids: #anchors\n",
    "            candidates=set()\n",
    "            for j in self.labels_train[i]: #same labels\n",
    "              candidates= candidates & set(class_imgs_train[j])\n",
    "            candidates= candidates - set([i]) #but the positive cant't be the anchor\n",
    "            if len(candidates)==0: # it dosen't exist\n",
    "              candidates= set(class_imgs_train[np.random.choice(self.labels_train[i])])-set([i]) # at least one\n",
    "            data.append( (i,  np.random.choice(list(candidates))) ) #random choice of candidates\n",
    "\n",
    "          np.random.shuffle(data) #very useful for breaking patterns\n",
    "          return class_imgs_train,data\n",
    "\n",
    "        def predict(self,query,split):\n",
    "            \"\"\"\n",
    "            the split defines where we are going to search\n",
    "            \"\"\"\n",
    "            if type(query) is not list:\n",
    "                query= [query]\n",
    "\n",
    "            i_input = self.visual_encoder(tf.nn.embedding_lookup(visual_matrix, query))\n",
    "            if split==\"val\":\n",
    "                    c_eval= self.visual_encoder(visual_matrix[self.val_ids])\n",
    "            if split==\"test\":\n",
    "                    c_eval= self.visual_encoder(visual_matrix[self.test_ids])\n",
    "            if split==\"train\":\n",
    "                    c_eval=self.visual_encoder(visual_matrix[self.train_ids])\n",
    "\n",
    "            rating= tf.matmul(i_input, tf.transpose(c_eval) )\n",
    "            return np.reshape(rating, [-1])\n",
    "\n",
    "        def metric(self,split, k=10):\n",
    "          \"\"\"\n",
    "          to compute metrics\n",
    "          \"\"\"\n",
    "          if split==\"val\":\n",
    "              ids,gt= self.val_ids,self.labels_val\n",
    "          if split==\"test\":\n",
    "              ids,gt= self.test_ids,self.labels_test\n",
    "\n",
    "          metric=0\n",
    "          for i in range(len(ids)): #querys\n",
    "            top= np.argsort(self.predict(ids[i],split))[::-1][1:k+1] #first one must be the query\n",
    "            #get labels\n",
    "            prediction= [gt[j] for j in top]\n",
    "            metric+=recall(gt[i], prediction)\n",
    "          return metric/len(ids) #average\n",
    "\n",
    "        def inference(self):\n",
    "          \"\"\"\n",
    "          testing phase\n",
    "          \"\"\"\n",
    "          results=(self.metric(\"test\",k=1), self.metric(\"test\",k=10), self.metric(\"test\",k=25))\n",
    "          print(results)\n",
    "          np.save(self.DIS_MODEL_FILE+\"test_metrics.npy\", np.array([results], dtype=object) )\n",
    "\n",
    "        def save(self, model_time, loss,recalls ):\n",
    "          \"\"\"\n",
    "          For saving logs of the experiment\n",
    "          \"\"\"\n",
    "          gpu_name=!nvidia-smi -L\n",
    "          with open(self.DIS_MODEL_FILE+'train.txt', 'w') as f:\n",
    "            f.write(\"training time of model: %fs\" % (model_time) + \"\\n\")\n",
    "            #f.write(\"finish epoch %s\" % epoch + \"with recall %s\" % best_recall  + \"\\n\")\n",
    "            f.write(gpu_name[0] + \"\\n\")\n",
    "          np.save(self.DIS_MODEL_FILE+\"Loss_recalls.npy\", np.array([loss,recalls],dtype=object))\n",
    "          #saving model\n",
    "          self.visual_encoder.save(self.DIS_MODEL_FILE+'visual_encoder_tf',save_format='tf')\n",
    "\n",
    "        def training(self):\n",
    "            \"\"\"\n",
    "            Training process\n",
    "            \"\"\"\n",
    "            recalls=[] #recall 1, 10, 25\n",
    "            loss_history=[]\n",
    "            start_time = time.time()\n",
    "            n_train=len(self.train_ids)\n",
    "            class_imgs_train,data= self.construct_train()\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                print(\"epoch: %d\" % epoch)\n",
    "                if epoch>=15: #decay\n",
    "                    self.optimizer.learning_rate.assign(0.00002) #VSE++\n",
    "\n",
    "                index = 0\n",
    "                while index + self.batch_size < n_train :\n",
    "                    input_A, input_P = get_batch_data(data, index,self.batch_size)  #anchor,positive\n",
    "                    index += self.batch_size\n",
    "                    input_N=[] #negatives\n",
    "\n",
    "                    if self.mode==\"random\":\n",
    "                      for anchor in input_A:\n",
    "                        candidates= set(self.train_ids) #all of them\n",
    "                        for j in self.labels_train[anchor]:\n",
    "                          candidates= candidates - set(class_imgs_train[j])\n",
    "                        input_N.append( np.random.choice(list(candidates)) )#Random negative\n",
    "\n",
    "                    else:  #Hard Negative\n",
    "                        rating= np.array(self.predict( list(input_A) , \"train\"), dtype=float)\n",
    "                        gc.collect()\n",
    "\n",
    "                        for i_ in range(self.batch_size):\n",
    "                            ratings_batch= rating[n_train*i_:n_train*(i_+1)]  #all images in train\n",
    "\n",
    "                            #-------- out ground truth----------\n",
    "                            for j in self.labels_train[input_A[i_]]:\n",
    "                              ratings_batch[ class_imgs_train[j]]= - np.infty #out imgs with same classes\n",
    "                            #-------- out ground truth----------\n",
    "                            input_N.append(self.train_ids[np.argmax(ratings_batch)])\n",
    "                            del ratings_batch\n",
    "                    with tf.GradientTape() as tape:\n",
    "                            losses= self.loss(input_A, input_P, input_N)\n",
    "\n",
    "                    grads = tape.gradient(losses, self.model.trainable_variables)\n",
    "                    self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "\n",
    "                print(\"loss:\",  losses.numpy() ,\"time: \", np.round(time.time() - start_time, 4))\n",
    "                loss_history.append(losses.numpy() )\n",
    "\n",
    "                #validation\n",
    "                print(\"Recall: 1-10-25 \",self.metric(\"val\",k=1), self.metric(\"val\",k=10), self.metric(\"val\",k=25))\n",
    "                recalls.append(( self.metric(\"val\",k=1), self.metric(\"val\",k=10), self.metric(\"val\",k=25) ))\n",
    "                break\n",
    "\n",
    "            #end\n",
    "            #save\n",
    "            self.save(time.time()-start_time, loss_history,recalls )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7-PIELwcPJt",
    "outputId": "ed0aa71f-9223-4316-9529-f7d723549ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Linear_\n",
      "epoch: 0\n",
      "loss: 0.20700344 time:  10.6632\n",
      "Recall: 1-10-25  0.4433333333333333 0.3721666666666666 0.35793333333333327\n"
     ]
    }
   ],
   "source": [
    "net =  triplet_model(data, labels, visual_matrix,1024,\"HN\",\"Linear\")\n",
    "net.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-YA9yiigFyJ",
    "outputId": "1fdbf383-e545-45bd-a6f4-2dde6d2e6abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Linear_\n",
      "pre train\n",
      "(0.35833333333333334, 0.3588333333333333, 0.3538)\n"
     ]
    }
   ],
   "source": [
    "net =  triplet_model(data, labels, visual_matrix,1024,\"HN\",\"Linear\",pretrain=True)\n",
    "net.inference()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
