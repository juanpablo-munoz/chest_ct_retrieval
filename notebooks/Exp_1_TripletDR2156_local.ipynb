{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea99a53-9589-4e99-8f99-2cfb15afbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "E:\\files\\Documents\\Proyecto Proximity\\chest_ct_retrieval\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# Add project root to PYTHONPATH\n",
    "project_root = os.getcwd()\n",
    "if str(project_root) not in sys.path and project_root.split('/')[-1] == 'chest_ct_retrieval':\n",
    "    sys.path.append(str(project_root))\n",
    "elif str(project_root) not in sys.path and project_root.split('/')[-1] == 'notebooks':\n",
    "    sys.path.append(str(os.path.normpath('/'.join(project_root.split('/')[:-1]))))\n",
    "\n",
    "%pwd\n",
    "%cd \"E:\\\\files\\\\Documents\\\\Proyecto Proximity\\\\chest_ct_retrieval\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9c02b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config.config import load_config\n",
    "from utils.seed import set_seed\n",
    "from training.setup import setup_training_run\n",
    "from training.environment import configure_environment\n",
    "from eval.metric_loader import load_metrics\n",
    "from training.data_setup_local import load_dataset, create_loaders\n",
    "from training.model_setup_local import initialize_model\n",
    "from training.trainer_local import Trainer\n",
    "\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "cfg = load_config(\"config/base_local.yaml\")\n",
    "\n",
    "set_seed(cfg[\"training\"][\"seed\"])\n",
    "\n",
    "run_dirs = setup_training_run(cfg[\"paths\"][\"dr2156\"][\"triplet_runs\"])\n",
    "\n",
    "checkpoints_dir = run_dirs[\"checkpoints\"]\n",
    "tensorboard_dir = run_dirs[\"logs\"]\n",
    "\n",
    "configure_environment(cfg)\n",
    "\n",
    "train_set, test_set, neg_compatibles = load_dataset(\n",
    "    cfg[\"paths\"][\"dr2156\"][\"preprocessed_300_int8\"], \n",
    "    cfg[\"training\"][\"seed\"], \n",
    "    float(cfg[\"dataset\"][\"train_frac\"]),\n",
    "    augmentations_arg=cfg[\"training\"][\"augmentations\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2667532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_vol, s_label = train_set[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "resize = tio.Compose([\n",
    "            #tio.Resize([100, 100, -1], image_interpolation='nearest'),\n",
    "            tio.RescaleIntensity(out_min_max=(-1000,200))\n",
    "        ])\n",
    "\n",
    "tio_image = tio.ScalarImage(tensor=s_vol, affine=np.eye(4))\n",
    "#tio_image = resize(tio_image)                \n",
    "\n",
    "s_vol = tio_image['data'][0]           # remove channel dimension → shape: [D, H, W]\n",
    "\n",
    "# Select middle slice in the axial (transverse) plane → [z, y, x]\n",
    "z_index = s_vol.shape[2] // 2\n",
    "axial_slice = s_vol[:, :, z_index]\n",
    "\n",
    "# Plot\n",
    "plt.imshow(axial_slice.numpy().astype(np.uint8), cmap='gray')\n",
    "plt.title(f'Axial Slice {z_index}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e43c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 100, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bf7e622f4445a2a1730211b9bd6cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### EPOCH 1 START ###\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453eaa8a5c124697a3752fda2d7126fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m\n\u001b[0;32m     50\u001b[0m p_metrics \u001b[38;5;241m=\u001b[39m load_metrics(cfg)\n\u001b[0;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     53\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_triplet\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     54\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_triplet\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m     accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[1;32mE:\\files\\Documents\\Proyecto Proximity\\chest_ct_retrieval\\training\\trainer_local.py:69\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m START ###\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Train stage\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m train_loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_train_loss \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mE:\\files\\Documents\\Proyecto Proximity\\chest_ct_retrieval\\training\\trainer_local.py:269\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp):\n\u001b[1;32m--> 269\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m#if type(outputs) not in (tuple, list):\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m#    outputs = (outputs,)\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     loss_inputs \u001b[38;5;241m=\u001b[39m outputs\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mE:\\files\\Documents\\Proyecto Proximity\\chest_ct_retrieval\\models\\networks.py:106\u001b[0m, in \u001b[0;36mProximity300x300.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m, h, w) \u001b[38;5;66;03m# x is 5D but Resnet expects a 4D input - so, let's squeeze the first dimension!\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m#print(\"squeezed input.shape:\", list(x.size()))\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m#print('resnet output shape:', x.size())\u001b[39;00m\n\u001b[0;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# Now, we bring back the first dimension for the 3DConvs!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    165\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, ceil_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[0;32m    166\u001b[0m                         return_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_indices)\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jpmm\\anaconda3\\envs\\Proximity\\Lib\\site-packages\\torch\\nn\\functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28minput\u001b[39m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from config.config import load_config\n",
    "from utils.seed import set_seed\n",
    "from training.setup import setup_training_run\n",
    "from training.environment import configure_environment\n",
    "from eval.metric_loader import load_metrics\n",
    "from training.data_setup_local import load_dataset, create_loaders\n",
    "from training.model_setup_local import initialize_model_triplets\n",
    "from training.trainer_local import Trainer\n",
    "\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "cfg = load_config(\"config/base_local.yaml\")\n",
    "\n",
    "set_seed(cfg[\"training\"][\"seed\"])\n",
    "\n",
    "run_dirs = setup_training_run(cfg[\"paths\"][\"dr2156\"][\"triplet_runs\"])\n",
    "\n",
    "checkpoints_dir = run_dirs[\"checkpoints\"]\n",
    "tensorboard_dir = run_dirs[\"logs\"]\n",
    "\n",
    "configure_environment(cfg)\n",
    "\n",
    "train_set, test_set, neg_compatibles = load_dataset(\n",
    "    cfg[\"paths\"][\"dr2156\"][\"preprocessed_300_int8\"], \n",
    "    cfg[\"training\"][\"seed\"], \n",
    "    float(cfg[\"dataset\"][\"train_frac\"]),\n",
    "    augmentations_arg=cfg[\"training\"][\"augmentations\"]\n",
    ")\n",
    "\n",
    "p_model, p_loss_fn, p_optimizer, p_scheduler = initialize_model_triplets(\n",
    "    embedding_size=int(cfg[\"model\"][\"embedding_size\"]),\n",
    "    margin=float(cfg[\"loss\"][\"margin\"]),\n",
    "    lr=float(cfg[\"training\"][\"optimizer\"][\"lr\"]),\n",
    "    weight_decay=float(cfg[\"training\"][\"optimizer\"][\"weight_decay\"]),\n",
    "    negative_compatibles_dict=neg_compatibles,\n",
    "    print_interval=int(cfg[\"logging\"][\"log_interval\"]),\n",
    "    cuda=cuda_available\n",
    ")\n",
    "\n",
    "loaders = create_loaders(\n",
    "    train_set,\n",
    "    test_set,\n",
    "    cfg[\"training\"][\"batch\"][\"n_classes\"],\n",
    "    cfg[\"training\"][\"batch\"][\"n_samples\"],\n",
    "    cuda_available\n",
    ")\n",
    "\n",
    "p_metrics = load_metrics(cfg)\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_loader=loaders[\"train_triplet\"],\n",
    "    val_loader=loaders[\"test_triplet\"],\n",
    "    train_eval_loader=loaders[\"train_eval\"],\n",
    "    val_eval_loader=loaders[\"test_eval\"],\n",
    "    train_full_loader=loaders[\"all_triplet_train\"],\n",
    "    val_full_loader=loaders[\"all_triplet_test\"],\n",
    "    model=p_model,\n",
    "    loss_fn=p_loss_fn,\n",
    "    optimizer=p_optimizer,\n",
    "    scheduler=p_scheduler,\n",
    "    n_epochs=cfg[\"training\"][\"n_epochs\"],\n",
    "    cuda=cuda_available,\n",
    "    log_interval=cfg[\"logging\"][\"log_interval\"],\n",
    "    checkpoint_dir=checkpoints_dir,\n",
    "    tensorboard_logs_dir=tensorboard_dir,\n",
    "    train_full_loader_switch=cfg[\"training\"][\"train_full_loader_switch\"],\n",
    "    metrics=p_metrics,\n",
    "    start_epoch=0,\n",
    "    accumulation_steps=3\n",
    ")\n",
    "trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d85cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tensor, model, subject  # or any other large variables\n",
    "import gc\n",
    "gc.collect()\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proximity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
